---
title: "P8105 homework 3"
author: "Shunyi Zhang"
output: github_document
editor_options: 
  chunk_output_type: console
---

This is my solution for homework 3.

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
```

# Problem 1 


## Get data
```{r}
data("instacart")
```


## Explore data
The dimension of this data is `r dim(instacart)`. It has `r nrow(instacart)` rows and `r ncol(instacart)` columns. It contains variables `r ls(instacart)`. 

It has variable for user `user_id`. Variables for orders are `order_id`, `order_dow`, and `order_hour_of_day`. Variables for products are `product_id` and `product_name`. There are also variables about aisle and department, `aisle`, `aisle_id`, `department`, and `department_id`.


## Explore aisle
```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

There are 134 aisles. Among them, the aisle of fresh vegetables is the most items ordered from.


## Make plot
```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle,n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


## Make table: popular item
```{r}
instacart %>% 
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(
    rank = min_rank(desc(n))
  ) %>% 
  filter(rank <= 3) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


## Makle table: mean hour
```{r}
instacart %>% 
	filter(
	  product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
	) %>% 
	group_by(
	  product_name, order_dow
	) %>% 
	summarize(
	  mean_hour = mean(order_hour_of_day)
	) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	) %>% 
  knitr::kable()
```



# Problem 2


## Get data
```{r}
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = "min_activity",
    values_to = "count_activity",
    names_prefix = "activity_"
  ) %>% 
  mutate(
    day = as.factor(day), 
    day_id = as.integer(day_id), 
    week = as.integer(week), 
    min_activity = as.double(min_activity)
  ) %>% 
  mutate(
    weekend_vs_weekday = recode(
      day, 
      Monday = "weekday", 
      Tuesday = "weekday", 
      Wednesday = "weekday", 
      Thursday = "weekday", 
      Friday = "weekday", 
      Saturday = "weekend", 
      Sunday = "weekend" 
    )
  ) %>% 
  mutate(
    day = factor(
      day, levels = c(
        "Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"
      )
    )
  ) %>% 
  relocate("day_id", "week", "day", "weekend_vs_weekday") %>% 
  arrange(week, day)
```

After steps of tidying, the clean data has a dimension of `r dim(accel_df)`. `day_id` represents the order of day for the study. `week`, `day`, and `weekend_vs_weekday` provide information about the day of study. `min_activity` and `count_activity` shows the count of activities at each minute of the day, recorded by the accelerometers.


## Make table: total activities
```{r}
accel_df %>% 
  group_by(week, day) %>% 
  summarise(sum_activity = sum(count_activity)) %>% 
  ggplot(aes(x = day, y = sum_activity, color = week)) +
  geom_point() + 
  facet_grid(week ~ .)
```

As shown in the graph, there is not a obvious trend between day and total activities. 


## Make plot: activity over a day
```{r}
accel_df %>% 
  ggplot(aes(x = min_activity, y = count_activity, color = day )) +
  geom_point(alpha = 0.3, size = 1) +
  geom_line(alpha = 0.3) + 
  labs(
    title = "Activity over the Course of the Day",
    x = "Time of the day",
    y = "Count of Activity",
    caption = "Data from accel_data.csv"
  ) + 
  scale_x_continuous(
    breaks = c(1, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("0:01", "3:00", "6:00", "9:00", "12:00", "15:00", "18:00", "21:00", "24:00")
  )
```

Reading from the graph, the time between 10:30pm to 6:00am has the total count relatively low. This time period should be the time for sleep having the low amount of activity. Around 9pm, the count of activity reaches the highest point. It should be the time for some gaming. At about 7am, 12pm, and 5pm, there are also high volumes of activity happen. There are about the breakfast, lunch, and dinner time. 



# Problem 3


## Get data
```{r}
data("ny_noaa")
```


## Data cleaning, explore snowfall
```{r}
ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, c("year", "month", "day"), sep = "-") %>% 
  mutate(
    year = as.factor(year), 
    month = as.factor(month), 
    day = as.factor(day), 
    prcp = as.numeric(prcp), 
    tmin = as.numeric(tmin), 
    tmax = as.numeric(tmax), 
    prcp = prcp / 10,
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = month.name[month]
  ) 

ny_noaa %>% 
  count(snow) %>% 
  arrange(desc(n))
```

Among the snowfall variable, 0mm is the most commonly observed value, means there is not a lot snow in the New York area.


