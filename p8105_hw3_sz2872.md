P8105 homework 3
================
Shunyi Zhang

This is my solution for homework 3.

# Problem 1

## Get data

``` r
data("instacart")
```

## Explore data

The dimension of this data is 1384617, 15. It has 1384617 rows and 15
columns. It contains variables add\_to\_cart\_order, aisle, aisle\_id,
days\_since\_prior\_order, department, department\_id, eval\_set,
order\_dow, order\_hour\_of\_day, order\_id, order\_number, product\_id,
product\_name, reordered, user\_id.

It has variable for user `user_id`. Variables for orders are `order_id`,
`order_dow`, and `order_hour_of_day`. Variables for products are
`product_id` and `product_name`. There are also variables about aisle
and department, `aisle`, `aisle_id`, `department`, and `department_id`.

## Explore aisle

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

There are 134 aisles. Among them, the aisle of fresh vegetables is the
most items ordered from.

## Make plot

``` r
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle,n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_sz2872_files/figure-gfm/unnamed-chunk-3-1.png" width="90%" />

## Make table: popular item

``` r
instacart %>% 
  filter(
    aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(
    rank = min_rank(desc(n))
  ) %>% 
  filter(rank <= 3) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

## Makle table: mean hour

``` r
instacart %>% 
    filter(
      product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")
    ) %>% 
    group_by(
      product_name, order_dow
    ) %>% 
    summarize(
      mean_hour = mean(order_hour_of_day)
    ) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    ) %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

| product\_name    |        0 |        1 |        2 |        3 |        4 |        5 |        6 |
| :--------------- | -------: | -------: | -------: | -------: | -------: | -------: | -------: |
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 | 15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 | 14.25000 | 11.55172 | 12.78431 | 11.93750 |

# Problem 2

## Get data

``` r
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    starts_with("activity"),
    names_to = "min_activity",
    values_to = "count_activity",
    names_prefix = "activity_"
  ) %>% 
  mutate(
    day = as.factor(day), 
    day_id = as.integer(day_id), 
    week = as.integer(week), 
    min_activity = as.double(min_activity)
  ) %>% 
  mutate(
    weekend_vs_weekday = recode(
      day, 
      Monday = "weekday", 
      Tuesday = "weekday", 
      Wednesday = "weekday", 
      Thursday = "weekday", 
      Friday = "weekday", 
      Saturday = "weekend", 
      Sunday = "weekend" 
    )
  ) %>% 
  mutate(
    day = factor(
      day, levels = c(
        "Monday","Tuesday","Wednesday","Thursday","Friday","Saturday","Sunday"
      )
    )
  ) %>% 
  relocate("day_id", "week", "day", "weekend_vs_weekday") %>% 
  arrange(week, day)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

After steps of tidying, the clean data has a dimension of 50400, 6.
`day_id` represents the order of day for the study. `week`, `day`, and
`weekend_vs_weekday` provide information about the day of study.
`min_activity` and `count_activity` shows the count of activities at
each minute of the day, recorded by the accelerometers.

## Make table: total activities

``` r
accel_df %>% 
  group_by(week, day) %>% 
  summarise(sum_activity = sum(count_activity)) %>% 
  ggplot(aes(x = day, y = sum_activity, color = week)) +
  geom_point() + 
  facet_grid(week ~ .)
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

<img src="p8105_hw3_sz2872_files/figure-gfm/unnamed-chunk-7-1.png" width="90%" />

As shown in the graph, there is not a obvious trend between day and
total activities.

## Make plot: activity over a day

``` r
accel_df %>% 
  ggplot(aes(x = min_activity, y = count_activity, color = day )) +
  geom_point(alpha = 0.3, size = 1) +
  geom_line(alpha = 0.3) + 
  labs(
    title = "Activity over the Course of the Day",
    x = "Time of the day",
    y = "Count of Activity",
    caption = "Data from accel_data.csv"
  ) + 
  scale_x_continuous(
    breaks = c(1, 180, 360, 540, 720, 900, 1080, 1260, 1440),
    labels = c("0:01", "3:00", "6:00", "9:00", "12:00", "15:00", "18:00", "21:00", "24:00")
  )
```

<img src="p8105_hw3_sz2872_files/figure-gfm/unnamed-chunk-8-1.png" width="90%" />

Reading from the graph, the time between 10:30pm to 6:00am has the total
count relatively low. This time period should be the time for sleep
having the low amount of activity. Around 9pm, the count of activity
reaches the highest point. It should be the time for some gaming. At
about 7am, 12pm, and 5pm, there are also high volumes of activity
happen. There are about the breakfast, lunch, and dinner time.

# Problem 3

## Get data

``` r
data("ny_noaa")
```

## Data cleaning, explore snowfall

``` r
ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(date, c("year", "month", "day"), sep = "-") %>% 
  mutate(
    year = as.factor(year), 
    month = as.factor(month), 
    day = as.factor(day), 
    prcp = as.numeric(prcp), 
    tmin = as.numeric(tmin), 
    tmax = as.numeric(tmax), 
    prcp = prcp / 10,
    tmin = tmin / 10,
    tmax = tmax / 10,
    month = month.name[month]
  ) 
```

    ## # A tibble: 2,595,176 x 9
    ##    id          year  month    day    prcp  snow  snwd  tmax  tmin
    ##    <chr>       <fct> <chr>    <fct> <dbl> <int> <int> <dbl> <dbl>
    ##  1 US1NYAB0001 2007  November 01       NA    NA    NA    NA    NA
    ##  2 US1NYAB0001 2007  November 02       NA    NA    NA    NA    NA
    ##  3 US1NYAB0001 2007  November 03       NA    NA    NA    NA    NA
    ##  4 US1NYAB0001 2007  November 04       NA    NA    NA    NA    NA
    ##  5 US1NYAB0001 2007  November 05       NA    NA    NA    NA    NA
    ##  6 US1NYAB0001 2007  November 06       NA    NA    NA    NA    NA
    ##  7 US1NYAB0001 2007  November 07       NA    NA    NA    NA    NA
    ##  8 US1NYAB0001 2007  November 08       NA    NA    NA    NA    NA
    ##  9 US1NYAB0001 2007  November 09       NA    NA    NA    NA    NA
    ## 10 US1NYAB0001 2007  November 10       NA    NA    NA    NA    NA
    ## # … with 2,595,166 more rows

``` r
ny_noaa %>% 
  count(snow) %>% 
  arrange(desc(n))
```

    ## # A tibble: 282 x 2
    ##     snow       n
    ##    <int>   <int>
    ##  1     0 2008508
    ##  2    NA  381221
    ##  3    25   31022
    ##  4    13   23095
    ##  5    51   18274
    ##  6    76   10173
    ##  7     8    9962
    ##  8     5    9748
    ##  9    38    9197
    ## 10     3    8790
    ## # … with 272 more rows

Among the snowfall variable, 0mm is the most commonly observed value,
means there is not a lot snow in the New York area.
